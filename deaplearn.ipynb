

import tensorflow as tf
import os
from tensorflow.keras.datasets import mnist
from tensorflow.keras.activations import relu
from tensorflow.keras.layers import Flatten,MaxPool2D,Activation,Conv2D,Dense,MaxPooling2D,Dropout,BatchNormalization
from tensorflow.keras.losses import sparse_categorical_crossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow import keras
from utils import mnist_reader
import matplotlib.pyplot as plt
import numpy as np

dataset = 'fashion'
os.chdir(r'E:\PTF\深度学习培训-南京\MLP')
os.getcwd()
train_images, train_labels = mnist_reader.load_mnist('data/' + dataset, kind='train')
train_images.shape
test_images,test_labels=mnist_reader.load_mnist('data/'+dataset,kind='t10k')
if dataset == 'mnist':
    class_names = ['0' ,'1', '2', '3', '4', '5', '6', '7', '8', '9']
else:
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

#训练数据
#训练集中有60,000个图像，每个图像表示为28 x 28(=784)像素：
#
train_labels
train_labels.shape
train_images = train_images.reshape(-1, 28, 28)
test_images = test_images.reshape(-1, 28, 28)
#测试集中有10,000个图像，每个图像表示为28 x 28像素：
test_images.shape
train_labels
test_labels
train_labels[0]
test_labels

#数据预处理

train_images.shape
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.gca().grid(False)
train_labels[0]

#在输入到神经网络模型之前，将图片的像素值缩放到0到1的范围。
train_images = train_images.reshape(-1, 28, 28,1)
test_images = test_images.reshape(-1, 28, 28,1)
train_images = train_images / 255.0
test_images = test_images / 255.0
import matplotlib.pyplot as plt
#%matplotlib inline
plt.figure(figsize=(15,15))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.yticks([])
    plt.grid('off')
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
#构建模型
#神经网络的基本单元是层（Layer）。
#Layers从他们的输入数据中学习表示（representations）。
#大多数深度学习模型都是将简单的Layer堆叠在一起，构建起复杂的模型。然后在训练期间学习每一层的参数。
##old model
model = keras.Sequential()
model.add(Conv2D(32, 3, strides=1, padding='same', input_shape=(28, 28, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(64, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(128, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(256, 3, strides=1, padding='valid',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.35))
model.add(Flatten())
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(128))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(10))
model.add(BatchNormalization())
model.add(Activation('softmax'))

##old model
model = keras.Sequential()
model.add(Conv2D(32, 3, strides=1, padding='same', input_shape=(28, 28, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(32, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(64, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.05))
model.add(Dense(10))
model.add(BatchNormalization())
model.add(Activation('softmax'))
##new model
model = keras.Sequential()
model.add(Conv2D(16, 3, strides=1, padding='same', input_shape=(28, 28, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, 3, strides=1, padding='same',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, strides=1, padding='valid',))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.05))
model.add(keras.layers.Dense(128))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.02))
model.add(keras.layers.Dense(10))
model.add(BatchNormalization())
model.add(Activation('softmax'))

tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)
model.summary()
#编译模型
#在模型进行训练之前，需要设置模型的训练参数，包括：
#    Loss function —模型的损失函数。在训练的过程中希望损失函数能够最小化，以学习到合适的参数。
#    Optimizer —模型的优化方法。
#    Metrics —模型的度量方法。
#这一操作在compile步骤中完成：
model.compile(optimizer=Adam(lr = 0.00075), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#该网络中的第一层tf.keras.layers.Flatten将输入图像从二维数组转换为大小28 * 28 = 784的一维数组。该层没有要学习的参数，它只重新格式化数据。
#网络由两个tf.keras.layers.Dense（全连接层）组成。
#第一个全连接层有128个神经元，使用relu激活函数。
#第二个全连接层包含10个节点，使用softmax激活函数。这一层返回一个大小为10的概率分布数组，每个位置包含一个概率值，表示当前图像属于某一类别的概率值。

#训练模型
#训练模型包括以下几个步骤：
#    将训练数据输入到模型中。例如，train_images 以及 train_labels。
#    模型学习图片到类别之间的映射关系。
#    在测试集上进行验证。
#使用model.fit 来训练模型，拟合训练数据。
model.fit(train_images, train_labels, epochs=3)
#评估模型
#接下来，我们在测试集上评估训练得到的模型参数。
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)

#模型保存
mp = "E://PTF/深度学习培训-南京/model1.h5"
model.save(mp)
#模型预测
#我们可以使用训练好的模型来预测一些图像。
predictions = model.predict(test_images)
predictions[0]
np.argmax(predictions[0])
test_labels[0]
#Let's plot several images with their predictions. Correct prediction labels are green and incorrect prediction labels are red.

# Plot the first 25 test images, their predicted label, and the true label

# Color correct predictions in green, incorrect predictions in red

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid('off')
    plt.imshow(test_images[i], cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions[i])
    true_label = test_labels[i]
    if predicted_label == true_label:
      color = 'green'
    else:
      color = 'red'
    plt.xlabel("{} ({})".format(class_names[predicted_label], 
                                  class_names[true_label]),
                                  color=color)
#使用训练好的模型预测一张图片
# Grab an image from the test dataset

img = test_images[4]
print(img.shape)
plt.figure()
plt.imshow(img)
plt.colorbar()
plt.gca().grid(False)

#tf.keras models are optimized to make predictions on a batch, or collection, of examples at once. So even though we're using a single image, we need to add it to a list:
# Add the image to a batch where it's the only member.

img = np.expand_dims(img,0)
print(img.shape)
predictions = model.predict(img)
print(predictions)
prediction = predictions[0]
prediction
np.argmax(prediction)
test_labels[1]